# LLM Testing Framework

AI-powered testing framework for Healthcare Chatbot using Playwright and Ollama.

## Architecture

This framework uses a **two-model approach**:

1. **Model 1 (`llama2:latest`)**: Generates diverse test prompts
2. **Model 2 (`gpt-oss:20b`)**: Validates chatbot response quality

## Features

- ðŸ¤– **AI-Powered Test Generation**: Automatically creates realistic test scenarios
- âœ… **Response Quality Validation**: Evaluates chatbot responses using LLM
- ðŸŽ­ **UI/UX Testing**: Comprehensive browser automation with Playwright
- ðŸ“Š **Detailed Reporting**: HTML reports with quality scores and metrics
- ðŸ”„ **End-to-End Testing**: Full conversation flow testing

## Prerequisites

- Node.js (v16+)
- Ollama installed and running
- Healthcare Chatbot running on `http://localhost:3000`
- Ollama models:
  - `llama2:latest` (for prompt generation)
  - `gpt-oss:20b` (for response validation)

## Installation

```bash
npm install
npx playwright install
```

## Configuration

Copy `.env.example` to `.env` and configure:

```bash
cp .env.example .env
```

## Running Tests

```bash
# Run all tests
npm test

# Run specific test suite
npm run test:response-quality
npm run test:appointment
npm run test:ui-interactions

# Run with UI mode
npm run test:ui

# Run in headed mode (see browser)
npm run test:headed
```

## Test Reports

View HTML reports:
```bash
npm run report
```

Reports are generated in `reports/html/`

## Project Structure

```
LLM-Testing-Framework/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ollama/           # Ollama integration
â”‚   â”œâ”€â”€ playwright/       # Playwright helpers
â”‚   â”œâ”€â”€ validators/       # Response validators
â”‚   â””â”€â”€ utils/           # Utilities
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ e2e/             # End-to-end tests
â”œâ”€â”€ config/              # Configuration files
â””â”€â”€ reports/             # Test reports
```

## How It Works

1. **Prompt Generation**: Model 1 generates test prompts
2. **Automation**: Playwright sends prompts to Healthcare Chatbot
3. **Response Capture**: Chatbot responses are captured
4. **Validation**: Model 2 evaluates response quality
5. **Reporting**: Results are compiled into reports

## Success Criteria

- Response quality score > 0.7 (70%)
- Medical accuracy validated
- UI interactions functional
- Performance within limits

## See Also

- [Project Architecture](PROJECT_ARCHITECTURE.md)
- [Healthcare Chatbot](../CreateChatbots/README.md)
